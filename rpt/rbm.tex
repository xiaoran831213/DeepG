\documentclass[11pt]{article}
\usepackage{textcomp,bbding,subfig}
\usepackage{float,amssymb,amsmath,amsfonts,bm}
\usepackage{graphicx,cite}
\usepackage[]{natbib}
\def\style{apa}
\usepackage[usenames,pdftex,dvips]{color,xcolor}
\usepackage{multirow,tabulary,colortbl,array}
\usepackage[normalem]{ulem}
\usepackage[colorlinks,bookmarksopen,bookmarksnumbered,citecolor=blue,urlcolor=blue]{hyperref}
\usepackage{moreverb,setspace}
\usepackage{algpseudocode}
\usepackage{algorithm}
%
% enable numbered boxes, with caption and label.
\makeatletter
\newcommand\fs@boxedtop
{
  \fs@boxed
  \def\@fs@mid{\vspace\abovecaptionskip\relax}
  \let\@fs@iftopcapt\iftrue
}
\makeatother
\floatstyle{boxedtop}
\floatname{framedbox}{Box}
\newfloat{framedbox}{tbp}{lob}
%
% Text layout
\topmargin -1.5cm
\oddsidemargin 0.0cm
\evensidemargin 0.0cm
\textwidth 16.5cm
\textheight 23.5cm
\setlength{\parindent}{0cm}

% Remove brackets from numbering in List of References
% \makeatletter \renewcommand\@biblabel[1]{} \makeatother
\makeatletter
\renewcommand{\@biblabel}[1]{\quad#1.}
\makeatother
% 
\allowdisplaybreaks[2]          % to accomodate long proofs spanning over pages
% 
% aliasis
\newcommand{\bs}{\boldsymbol}
\newcommand{\mean}[2]{\left\langle{#1}\right\rangle_{#2}}
\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}
%
% vectors and matrices
\newcommand{\vb}{\boldsymbol{b}}
\newcommand{\vc}{\boldsymbol{c}}
\newcommand{\vh}{\boldsymbol{h}}
\newcommand{\vv}{\boldsymbol{v}}
\newcommand{\vx}{\boldsymbol{x}}
\newcommand{\vw}{\boldsymbol{w}}
\newcommand{\vs}{\boldsymbol{s}}
% 
\newcommand{\md}{\boldsymbol{D}}
\newcommand{\mv}{\boldsymbol{V}}
\newcommand{\mh}{\boldsymbol{H}}
\newcommand{\mw}{\boldsymbol{W}}
\newcommand{\mx}{\boldsymbol{X}}
% 
% with hats or tildes
\newcommand{\vbt}{\tilde{\vb}}
\newcommand{\vct}{\tilde{\vc}}
\newcommand{\vht}{\tilde{\vh}}
\newcommand{\vvt}{\tilde{\vv}}
\newcommand{\vvp}{\vv^{\prime}}
\newcommand{\mwt}{\tilde{\mw}}
\newcommand{\vxt}{\tilde{\vx}}
\newcommand{\vhh}{\hat{\vh}}
\newcommand{\vvh}{\hat{\vv}}
% 
% xiaoran's edit
\newcommand{\xadd}[1]{\textcolor{blue}{#1}}
\newcommand{\xdel}[1]{\textcolor{red}{\sout{#1}}}
\newcommand{\xrpl}[2]{\xdel{#1}\xadd{#2}}
\newcommand{\xacc}[1]{\textcolor{ForestGreen}{#1}}
% 
% encoders
% vector or matrix
\newcommand{\vecEC}[1]{\boldsymbol{#1}}
% 
% decoders
\newcommand{\vecDC}[1]{\boldsymbol{\tilde{#1}}} 
% 
\newcommand{\xVO}{\boldsymbol{x}}         % the x vector, original
\newcommand{\xVR}{\boldsymbol{\tilde{x}}} % the x vector, recovered
\newcommand{\xSO}{x}                      % the x scaler, original
\newcommand{\xSR}{\tilde{x}}              % the x scaler, recovered
% 
% the vector of ones
\newcommand{\one}{\boldsymbol{1}}
% the diagnal matrix
\newcommand{\I}[1]{\boldsymbol{I}^{#1}}
% 
% parameters in the neural network
\newcommand{\Par}{\boldsymbol{\Theta}}
\newcommand{\pEC}{\boldsymbol{\theta}}
\newcommand{\pDC}{\boldsymbol{\tilde{\theta}}}
% 
% Loss function in Cross Entropy form
\newcommand{\LCE}[2]{#1\log{#2} + (1-#1)\log{(1-#2)}}
% 
% derivative
\newcommand{\DRV}[2]{\frac{d #1}{d #2}}
\newcommand{\DRC}[3]{\DRV{#1}{#2}\DRV{#2}{#3}}
\newcommand{\PDV}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\PDC}[3]{\PDV{#1}{#2}\PDV{#2}{#3}}
% 
% invers logit, aka. sigmoid function
\newcommand{\SGM}[1]{\frac{1}{1+e^{-#1}}}
% 
% assign to diagnoral
\newcommand{\diag}[1]{\text{diag} (#1)}
% identity matrix
\newcommand{\im}{\textrm{\textbf{I}}}
% 
% declarations
% argument of the minimum / maximum
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

% \pagestyle{headings}

% \author{Xiaoran Tong, Qin Lu} 
\doublespacing
\begin{document}
\title{A note on Boltzmann Machine, Restricted Boltzmann Machine, and Deep Belief Network}
\maketitle
\begin{flushleft}
  Xiaoran Tong\textsuperscript{1},
  Qin Lu\textsuperscript{1*},
  \\
  \bigskip
  \textbf{1} Department of Epidemiology and Biostatistics, Michigan State University, East Lansing, USA

  \vskip 50ex
  Correspondence: Qing Lu\\
  Department of Epidemiology and Biostatistics\\
  College of Human Medicine\\
  Michigan State University\\
  909 Fee Road\\
  East Lansing, MI 48824-1030\\
  qlu@msu.edu\\
\end{flushleft}

\clearpage
\begin{abstract}
  This research note covers the basics of Restricted Boltman Machine, a energy based, generative neural network.
\end{abstract}
\clearpage

\section{Boltzmann Machine}
\subsection{Concept}
A Boltzmann Machine (BM) is an engergy based model for binary data generation process, who views the observed data as the fraction of a physics system on display. In the complete system, the observed $P$ dimensional data is in fact the realization of its $P$ visible units, denoted by vector $\vv$, besides which there are presumably $Q$ hidden units holding unobserved data, denoted by vector $\vh$. All units are allowed to connect with each other to form mutual dependencies, as Figure \ref{fig:gbm} illustrates:
\begin{figure}[h]
  \centering
  \includegraphics[width=200px]{img/gbm.png}
  \caption{Boltzmann Machine.}\label{fig:gbm}
\end{figure} \\
Together, the assignment of $\vv$ and $\vh$ comprices a complete $P+Q$ dimensional state vector $\vs =(\vv, \vh)$ of the system. Each distinct state is characterized by its energy, measurable by an energy function $E(\vs) = E(\vv, \vh)$. By the rule of nature, when a system reaches thermal equilibrium, states of lower engery are more likelly to sustain (thus more prevalent) than those of higher energy. Upholding this rule, the probability of a specific state $\vs=(\vv, \vh)$ presenting itself in the system, is proportional to the exponential of the negative energy of the said state, that is,
\begin{equation} \label{eq:p(s)}  % probability of observing a complete state
  \begin{split}
    \Pr(\vs) = \Pr(\vv, \vh) = \frac{e^{-E(\vv, \vh)}}{Z}, \quad Z = \int_{\vv,\vh} e^{-E(\vv, \vh) \,d\vv\,d\vh},
  \end{split}
\end{equation}
which is a Boltzmann distribution that assigns lower engery states higher density and vise versa. The partition function $Z$ serves as a normalizing constant to ensure $\int_{\vv, \vh} \Pr(\vv, \vh) \,d\vv\,d\vh = 1$. It is readily seen that engergy function $E(\vv, \vh)$ determines the system's dynamic behovior, it is therefore carefully choosen to allow emulation of the natural process that have given rise to the binary visible data we have collected. A Boltzmann Machine defines a binary system with energy function
\begin{align*}\label{eq:e(s)} % system energy for generic boltzmann machine
    E(\vv, \vh) = E(\vs) = -\sum_{i=1}^{P+Q} b_i s_i - \sum_{1 = i < j}^{P+Q} s_i w_{ij} s_j \numberthis
\end{align*}
where $b_i$ is an offest, serving as the energy thresholds to ``turn off'' the $i$ th unit $s_i$; $w_{ij}$ is the connection between the $i$ th and $j$ th units. The first term depicts that $s_i$ is more likely to stay ``on'' if $b_i$ is larger, because a system state that already has $s_i$ ``on'' demands lower energy to maintain (Eq.\,\ref{eq:e(s)}), it is therefore less likely for the system to jump out of such a state (Eq.\,\ref{eq:p(s)}); another way to see it, is that for the system to own a fair (50\%) chance of turning off $s_i$ under no interference form the other units, it must raise an extra $b_i$ energy. The second terms mode the mutual between $s_i$ and the others. Stronger connection promote binary agreement (when positive) or opposition (when negative) between $s_i$ and $s_j$, whereas weaker connection diminishes the mutual influcene between the two. The energy function is thus paramterized by $P+Q$ offsets and $P+Q \choose 2$ undirected connections, we represent them by $\pEC = \{b_i, m_{ij} | 1 \le i < j \le P+Q\}$.
\subsection{Evolution of Bolztmann Machine}
The probability of a particular unit $s_k, (k = 1, \dots, P+Q)$ being turned on in the next stage is, given current state of the other units $\vs_{k-}$:
\begin{equation}\label{eq:p(s_k=1)}
  \Pr(s_k = 1|\vs_{k-}) = \sigma(b_k + \sum_{i=1, i \ne k}^{P+Q}{s_i w_{ik}})
\end{equation}
Here,  $\sigma(x) = [1 + \exp({-x})]^{-1}$ is the sigmoid (logistic) function; $\vs_{k-}$ denote all units' value in the system, visible and hidden alike, except $s_k$. \\
Proof: start by splitting the energy contributed by the $k$ th unit from the rest,
\newcommand{\st}{\tilde{s}}
\begin{align*}
  E(\vs)
  & = \left( -\sum_{i=1, i \ne k}^{P+Q} b_i s_i - \sum_{1 \le i < j, i \ne k, j \ne k}^{P+Q} s_i w_{ij} s_j \right) + \left(-b_k s_k - \sum_{i=1, i \ne k}^{P+Q}s_i w_{ik} s_k \right) \\
  & = E(\vs_{-k}) + E(s_k), \\
  \Rightarrow \Pr(s_k | \vs_{k-})
  & = \int_{\vs_{-k}} \Pr(\vs) d\vs_{-k} = \frac{1}{Z} \int_{\vs_{-k}} e^{-E(\vs)} d\vs_{-k} \Leftarrow (\ref{eq:p(s)}) \\
  & = \frac{\int_{\vs_{-k}} e^{-E(\vs)} d\vs_{-k}}{\int_{\vs} e^{-E(\vs)} d\vs} \\
  & = \frac{e^{-E(s_k)} \int_{\vs_{-k}} e^{-E(\vs_{-k})} d\vs_{-k}}  {\int_{\st_k} \int_{\vs_{-k}} e^{-E(\vs_{-k})} d\vs_{-k}\,d\st_k} \\
  & = \frac{e^{-E(s_k)} \int_{\vs_{-k}} e^{-E(\vs_{-k})} d\vs_{-k}}  {[e^{-E(\st_k)}|_{\st_k=1} + e^{-E(\st_k)}|_{\st_k=0}] \int_{\vs_{-k}} e^{-E(\vs_{-k})} d\vs_{-k}} \\
  & = \frac{e^{-E(s_k)}}{e^{-E(\st_k)}|_{\st_k=1} + e^{-E(\st_k)}|_{\st_k=0}} \\
  % 
  \Rightarrow \Pr(s_k=1 | \vs_{k-})
  & = \frac{e^{-E(s_k)}|_{s_k=1}}{e^{-E(\st_k)}|_{\st_k=1} + e^{-E(\st_k)}|_{\st_k=0}} \\
  & = \frac{e^{b_k + \sum_{i=1, i \ne k}^{P+Q}{s_i w_{ik}}}}{e^{b_k + \sum_{i=1, i \ne k}^{P+Q}{s_i w_{ik}}} + e^{0}} \\
  & = \frac{1}{1 + e^{-b_k - \sum_{i=1, i \ne k}^{P+Q}{s_i w_{ik}}}} \\
  & = \sigma(b_k + \sum_{i=1, i \ne k}^{P+Q}{s_i w_{ik}}).
\end{align*}
\begin{framedbox}[h]
  \caption{Attempt to vecterize a Boltzmann Machine} \label{box:vgbm}
  \centering
  \begin{minipage}{1\linewidth}
    \small It might be tempting to simultaneously evaluate Eq.\,\eqref{eq:p(s_k=1)} for all or a batch units so the system state can be advanced faster, given the abundance of modern computation packages
    (e.g.\,\textbf{R}, \textbf{Python-Numpy}, \textbf{Matlab}, etc.) that support highly optimized linear algebra operation, tensor broadcasting, and transparent parallelism on multi-processor hardware,
    such that
    \begin{equation*}
      \left[
        \begin{array}{c}
          \Pr(s_1^{(t+1)} = 1)   \\
          \Pr(s_2^{(t+1)} = 1)   \\
          \vdots \\
          \Pr(s_k^{(t+1)} = 1)   \\
          \vdots \\
          \Pr(s_K^{(t+1)} = 1)
        \end{array}
      \right] =
      \left[
        \begin{array}{c}
          \sigma(b_1 + \sum_{i \ne 1}^K{s_i^{(t)} w_{i,1}}) \\
          \sigma(b_2 + \sum_{i \ne 2}^K{s_i^{(t)} w_{i,2}}) \\
          \vdots \\
          \sigma(b_k + \sum_{i \ne k}^K{s_i^{(t)} w_{i,k}}) \\
          \vdots \\
          \sigma(b_K + \sum_{i \ne K}^K{s_i^{(t)} w_{i,K}}) \\
        \end{array}
      \right] = \sigma(\vb + \mw\vs^{(t)}),
    \end{equation*}
    where $K=P+Q$ is the total number of units in the system; $\vb$ is the $K$ dimensional vector of unit biases; $\mw$ is the $K \times K$ symmetric, 0 diagonal, undirected graph matrix, whose $(i, j)$ th
    entry (as well as the $(j, i)$ th) gives the connection between unit $i$ and $j$ when $i \ne j$; $\vs^{(t+1)}$ and $\vs^{(t)}$ denote the system state in the next and current stages, respectively. This
    vecterized operation is commonly one line of coding by most of the aforementioned tools. \\
    This is rendered futile, however, by the fact that all units are fully connected, which means altering one affects the activation probability of the rest. Therefore, to run a Boltzmann Machine we have to
    evolve the units one by one. Experiments shows advancing all units together causes the system to diverge - it will not reach thermal equilibrium.    
  \end{minipage}
\end{framedbox}
\subsection{MLE of Boltzmann Machine}
The best interest is to fine tune the flexible parameters $\pEC=\{b_i, w_{ij} | 1 \le i < j \le P+Q \}$ in such a way that the odds of observing the $N$ empirical data points $\mv=[\vv_1, \dots, \vv_N]^T$ on the visible units are maximized, which is equivalent to maximizing the marginal Boltzman distribution $\Pr(\vv, \vh)$ over assignments of $\vh$:
\begin{equation} \label{eq:p(v)}  % probability of observing a visible portion
  \begin{split}
    \Pr(\vv) = \int_{\vh}{\Pr(\vv, \vh)d\vh} = \frac{1}{Z} \int_{\vh}{e^{-E(\vv, \vh)}d\vh}.
  \end{split}
\end{equation}
The tuning requires the gradient of negative log likelihood with respect to $\pEC$ to decide updating rules, such that
\[ \pEC^{t+1} = \pEC^t + \epsilon \PDV{-\log{\Pr(\vv)}}{\pEC}, \]
where $\pEC^{t+1}$ is the resulting parameters of $t$ iterative updates, and $\epsilon$ is the learning rate. Now introduce the gradient expression:
\begin{align}\label{eq:gv1}
  -\PDV{\log{\Pr(\vv)}}{\pEC} &= -\PDV{\log{\int_{\vh}{e^{-E(\vv, \vh)}d\vh}}}{\pEC} + \PDV{\mean{\log{\int_{\vh}{e^{-E(\vvt, \vh)}d\vh}}}{\vvt}}{\pEC}.
\end{align}
The angled bracket $\mean{\dots}{\mx}$ denotes the expected value of an expression over random variable $\mx$.
There are a number of ways to interpret the gradient terms. The first term (without sign) is referred as \textbf{positive phase}, due to the fact that increases this term increases the likelihood of $\vv$; for the same reason, the second term (without sign) is called \textbf{negative phase}.\\
Derivation of (\ref{eq:gv1}):
\begin{align*}
  -\PDV{\log{\Pr(\vv)}}{\pEC}
  & = -\PDV{\log{\int_{\vh}{e^{-E(\vv, \vh)}d\vh}}}{\pEC} + \PDV{\log{\int_{\vvt, \vh} e^{-E(\vvt, \vh)} d\vvt\,d\vh }}{\pEC} \quad \Leftarrow (\ref{eq:p(s)}, \ref{eq:p(v)}) \\
  \textrm{\textbf{Positive phase:}} & \textrm{ Done!} \\
  \textrm{\textbf{Negative phase:}} \\
  \PDV{\log{\int_{\vvt, \vh} e^{-E(\vvt, \vh)} d\vvt\,d\vh }}{\pEC}
  & = \frac{1}{\int_{\vvt, \vh} e^{-E(\vvt, \vh)} d\vvt\,d\vh} \PDV{\int_{\vvt}\int_{\vh} e^{-E(\vvt, \vh)} d\vh\,d\vvt}{\pEC} \\
  & = \frac{1}{Z} \int_{\vvt} \PDV{ \int_{\vh}{e^{-E(\vvt, \vh)}}d\vh }{ \pEC } d\vvt \quad \Leftarrow (\ref{eq:p(s)}),\,\textrm{sum rule in deferenciation} \\
  & = \int_{\vvt}  \frac{1}{Z}\int_{\vh} e^{-E(\vvt, \vh)} d\vh \PDV{\log{\int_{\vh} e^{-E(\vvt, \vh) d\vh}}}{\pEC}  d\vvt \quad \Leftarrow \PDV{f(\vx)}{\vx}=f(\vx)\PDV{\log{f(\vx)}}{\vx} \\
  & = \int_{\vvt}{\Pr(\vvt) \PDV{\log{\int_{\vh}{e^{-E(\vvt, \vh)}d\vh}}}{\pEC}}d\vvt \quad \Leftarrow (\ref{eq:p(v)}) \\
  & = \mean{\PDV{\log{\int_{\vh}{e^{-E(\vvt, \vh)}d\vh}}}{\pEC}}{\vvt} \\
  & = \PDV{\mean{\log{\int_{\vh}{e^{-E(\vvt, \vh)}d\vh}}}{\vvt}}{\pEC} \quad (\textrm{Done!}).
\end{align*}
The above gradient form (\ref{eq:gv1}) is not ideal for direct implementation, since the update rule still involves gradient for both positive and negative phase, but it is meant for symbolic expression packages such as python theano which automatically program gradient function once the objective (or pseudo objective) function has been programmed. For low level implementation though, the update rules has to be gradient free, rearrange (\ref{eq:gv1}) we see
\begin{align*}
  \textrm{Positive Phase:}
  & \\
  \PDV{\log{\int_{\vh}{e^{-E(\vv, \vh)}d\vh}}}{\pEC} 
  & = \frac{1}{\int_{\vht} e^{-E(\vv, \vht)} d\vht}   \PDV{\int_{\vh} e^{-E(\vv, \vh)} d\vh}{\pEC}  \\
  & = \frac{1}{\int_{\vht} e^{-E(\vv, \vht)} d\vht}   \int_{\vh} \PDV{ e^{-E(\vv, \vh)}}{\pEC} d\vh \\
  & = \frac{1}{\int_{\vht} e^{-E(\vv, \vht)} d\vht}   \int_{\vh} e^{-E(\vv, \vh)}\PDV{-E(\vv, \vh)}{\pEC} d\vh \\
  & = \frac{1}{ \frac{1}{Z}  \int_{\vht} e^{-E(\vv, \vht)} d\vht}  \int_{\vh} \frac{e^{-E(\vv, \vh)}}{Z} \PDV{-E(\vv, \vh)}{\pEC} d\vh \\
  & = \frac{1}{\Pr(\vv)}  \int_{\vh} \Pr(\vv, \vh)\PDV{-E(\vv, \vh)}{\pEC} d\vh  & \Leftarrow (\ref{eq:p(s)})(\ref{eq:p(v)}) \\
  & = -\int_{\vh} \frac{\Pr(\vv, \vh)}{\Pr(\vv)} \PDV{E(\vv, \vh)}{\pEC} d\vh \\
  & = -\int_{\vh} \Pr(\vh | \vv) \PDV{E(\vv, \vh)}{\pEC}  d\vh \\
  & = -\mean{\PDV{E(\vv, \vh)}{\pEC}}{\vh|\vv} \\
  \textrm{Negative Phase:}p
  & \\
  \PDV{\mean{\log{\int_{\vht}{e^{-E(\vvt, \vht)}d\vht}}}{\vvt}}{\pEC}
  &= \mean{\PDV{\log{\int_{\vht}{e^{-E(\vvt, \vht)}d\vht}}}{\pEC}}{\vvt} \\
  &= \mean{ -\mean{\PDV{E(\vvt, \vht)}{\pEC}}{\vht|\vvt}  }{\vvt} \\
  &= -\mean{\PDV{E(\vvt, \vht)}{\pEC}}{\vvt, \vht}.
\end{align*} 
Thus we could rewrite ({\ref{eq:gv1}) in terms of expected value:
\begin{align} \label{eq:gv2}
  -\PDV{\log{\Pr(\vv)}}{\pEC} = \mean{\PDV{E(\vv, \vh)}{\pEC}}{\vh|\vv} - \mean{\PDV{E(\vvt, \vht)}{\pEC}}{\vvt, \vht}
\end{align}
The gradients still exists on the right side, but it only involves energy function itself without either logarithm or exponentiation. The positive and negative phases (see \ref{eq:gv1}) are now re-expressed by two expectation terms, which is commonly referred as \textbf{data} phase and \textbf{model} phase, because the former is influenced by imperically observed data $\vv$ through conditioning, and the later entirely relying on a Boltzmann Machine runing freely without the interference of any substantial reality. From the above equation (\ref{eq:gv2}) we can now reinterprete the update rules by viewing the ``loss'' as the difference of expected energy between a system ``forced'' to generate observed $\vv$ on its $P$ visible units, and another system of identical topology but freely operate without any constraint. Therefore, minimizing this difference via its negative gradient w.r.t. machine parameters $\pEC=\{\mw, \vb\}$, amounts to urge the machine to generate $\vvt$ on its own, thus mimicking the nature process that had given rise to the training material we observed, and hopefully achieving satisfying generalization performance with the aid of hidden units.
Now, taking advantage of the simple form of energy function for a Boltzmann distribution (see \ref{eq:e(s)}), we immediately see
\begin{align} \label{eq:ge}
  \PDV{E(\vs)}{w_{ij}} = s_i s_j,  \quad \PDV{E(\vs)}{b_i} = s_i, \quad  (1 \le i < j \le P+Q)
\end{align}
Joint (\ref{eq:ge}) and (\ref{eq:gv2}) we get the primative update rules for the MLE of $\Pr(\vv)$:
\begin{align*} \label{eq:gv3}
  -\PDV{\log{\Pr(\vv)}}{w_{ij}} &= \mean{s_i s_j}{\vh|\vv} - \mean{s_i s_j}{\vvt, \vht} \\
  -\PDV{\log{\Pr(\vv)}}{b_i}    &= \mean{s_i}{\vh|\vv} - \mean{s_i}{\vvt, \vht} \numberthis \\
  \textrm{where }               & 1 \le i < j \le P+Q.
\end{align*}
The interpretation of update rules are straight forward, for $w_{ij}$ - the connection between $s_i$ and $s_j$, it is the difference of unit $i$ and $j$'s covariance between a system whose visible units are clumped on empirical sample, and the same system that has been set for free run; as for $b_i$ - the unit offset (de-activation threshold) of $s_i$, the update rule is the difference of mean value on the $i$ th unit, between the clumped system and same systems freely run. At this point, we are readly to write down the one sample MLE algorithm for a Bolztmann Machine:
\begin{algorithm}[h]
  \caption{One sample update rule for Boltzmann Machine}\label{alg:gbm1}
  \begin{algorithmic}[1]
    \State Clump $P$ dimenional obsevation on $P$ visible units $\vv$ \Comment{\textbf{Positive} Phase}
    \Repeat                                                           \Comment{burn in}
    \State one by one advance the state of $s_k$ if $s_k \in \vh$     \Comment{(Eq.\,\ref{eq:p(s_k=1)})}
    \Until{$\vh$ reaches thermal equilibrium}
    \Repeat                                                           \Comment{sampling}
    \State one by one advance the state of $s_k$ if $s_k \in \vh$     \Comment{(Eq.\,\ref{eq:p(s_k=1)})}
    \State Store $\vs=(\vv, \vh)$
    \Until{enough sample of $\vs$ is gathered}
    \State $\mean{s_i s_j}{\vh|\vv} \approx$ proportion of times both $s_i$ and $s_j$ are on
    \State $\mean{s_i}{\vh|\vv} \approx$ proportion of times $s_i$ is on
    \Statex

    \State Relex the constraint on $P$ visible units $\vv$            \Comment{\textbf{Negative} Phase}
    \Repeat                                                           \Comment{burn in}
    \State one by one advance the state of $s_k$                      \Comment{(Eq.\,\ref{eq:p(s_k=1)})}
    \Until{$\vs$ reaches thermal equilibrium}
    \Repeat                                                           \Comment{sampling}
    \State one by one advance the state of $s_k$                      \Comment{(Eq.\,\ref{eq:p(s_k=1)})}
    \State Store $\vs=(\vv, \vh)$
    \Until{enough sample of $\vs$ is gathered}
    \State $\mean{s_i s_j}{\vvt, \vht} \approx$ proportion of times both $s_i$ and $s_j$ are on
    \State $\mean{s_i}{\vvt, \vht} \approx$ proportion of times $s_i$ is on
    \Statex

    \State $-\Delta w_{ij} \gets \mean{s_i s_j}{\vh|\vv} - \mean{s_i s_j}{\vvt, \vht}$ 
    \State $-\Delta b_{i} \gets \mean{s_i}{\vh|\vv} - \mean{s_i}{\vvt, \vht}$ 
    \State \Return $-\Delta \mw$ and $-\Delta \vb$
  \end{algorithmic}
\end{algorithm} \\
Although the update rules has sample form, the exact values of $\mean{s_i s_j}{\vh|\vv}$, $\mean{s_i}{\vh|\vv}$, as well as $\mean{s_i s_j}{\vvt, \vht}$, $\mean{s_i}{\vvt, \vht}$, are computationally intractable because they involves going through either all $P+Q \choose 2$ states (for negative phase) or $Q \choose 2$ hidden states (for positive phase). Therefore we resolved to Gibbis sampling for approximations of the four mean values. Still, the sampling requires considerable time, and the resulting update rules is a noisy gradient of $\Pr(\vv)$ w.r.t. $\mw$ and $\vb$. Thus, Boltzmann Machine is unfit for problems involving large number of variables, a issue somewhat mitigated by relpacing the Gibbs sampling procedure with mean field approximation (will be included in this note in the future).
The expansion of the one sample update rule to a batch of $N$ samples is straight forward, just apply Algorithm \ref{alg:gbm1} to each sample then take the mean over $N$ sets of update rules.
% new subsection
\section{Restricted Boltzmann Machine}
\subsection{Concept}
In a Bolzmann Machine (BM), units are fully connected with each other, the preceding ``Restricted'' highlights additional constraints that connection is forbidden among visible units, as well as among hidden units, while full connection is still established between the two, see Figure \ref{fig:rbm} for an illustration.
\begin{figure}[h]
  \centering
  \includegraphics[width=100px]{img/rbm.png}
  \caption{The Restricted Boltzmann Machine.}\label{fig:rbm}
\end{figure}
\subsection{Thermal dynamics of a RBM}
Much like the more general Boltzmann Machine (BM), the behavior of a RBM system is also governed by an engergy function $E(\vv, \vh)$ parameterized by unit biasis and inter-unit connections of similar depiction:
\begin{equation} \label{eq:rbm:e(s)}
  E(\vv, \vh) = -\sum_{i=1}^{P}{b_i v_i} - \sum_{j=1}^{Q}{c_j h_j} - \sum_{i=1}^P\sum_{j=1}^Q{v_i w_{ij} h_j} = -\vv^T\vb - \vc^T\vh - \vv^T \mw \vh,
\end{equation}
where $b_i, (i=1, \dots, P)$ is the bias of the $i$ th visible units $v_i$, which shows the amont of energy would be taken away when $v_i$ is ``on'' (or extra energy required to have a fair chance turning it off), that is, larger $b_i$ means lower total energy when $v_i$ is ``on'' and states with $v_i=1$ are thus more stable (i.e.,\,more likely to be seen); the bias $c_j, (j=1, \dots, Q)$ on the $j$ th hidden unit $h_j$ is seen quite the same way, larger $c_j$ makes states having $h_j$ turned ``on'' harder to turn away from; $w_{ij}$ shows connection between the $i$ th visible and $j$ th hidden units, a large value either encourages (when positive) or prohibits (when negative) co-activation of $v_i$ and $h_j$, conversely, a small $w_{ij}$ diminish mutual dependency of the two. We can see the terms involving visible and hidden units are separable for a RBM, due to the absence of hidden-hidden and visible-visible link. \\
Exploiting the restriction, instead of one unit at a time, a RBM can evolve itself by double batches, that is, simultaneously advancing all hidden units given the current state of visible units, and vise versa, in a manner of back and forth shown below:
\begin{align*}
  \Pr(v_i=1|\vh) & = \sigma(b_i + \sum_{j=1}^Q{w_{ij} h_j}), \quad i = 1, \dots, P; \numberthis \label{eq:rbm:p(v|h)} \\
  \Pr(h_j=1|\vv) & = \sigma(c_j + \sum_{i=1}^P{v_i w_{ij}}), \quad j = 1, \dots, Q. \numberthis \label{eq:rbm:p(h|v)}
\end{align*}
\textbf{Proof}: \\
\newcommand{\jt}{\tilde{j}}
\newcommand{\wt}{\tilde{w}}
\newcommand{\bt}{\tilde{b}}
\newcommand{\ct}{\tilde{c}}
A RBM is a special case of the BM with identical assemble of visible and hidden units except that any connection $w_{ij}$ is forced to zero whenever $s_i$ and $s_j$ are both visible or both hidden. Without loss of generality, let the $i$ th visible unit $v_i$ in the RBM also be the $i$ th unit $s_i$ of the parental BM: $\vs=(\vv, \vh)$, where $i=1, \dots, P$; let the $\jt$ th hidden unit $h_{\jt}$ in the RBM be the $P+\jt$ th unit $s_{P+\jt}$ of the parental BM, where $\jt=1, \dots, Q$; lastly, let $\wt_{i\jt}$ = $w_{i,P+\jt}$, $\bt_i = b_i$, and $\ct_{\jt} = b_{P+\jt}$, where $\wt$, $\bt$ and $\ct$ denotes connections and biases of the RBM while $w$ and $b$ denote the connection and bias in the parental BM.
\begin{align*}
  \Pr(s_i=1|s_{i-}) & = \Pr(v_i=1|v_{i-}, \vh)                                  & \Leftarrow (\textrm{relabeling}) \\
                    & = \Pr(v_i=1|\vh)                                          & \Leftarrow v_i \perp \vv_{i-}    \\
  \Pr(s_i=1|s_{i-}) & = \sigma(b_i + \sum_{j=1, j \ne i}^{P+Q}{w_{ij}s_j} )     & \Leftarrow (\ref{eq:p(s_k=1)})   \\
                    & = \sigma(b_i + \sum_{j=1, j \ne i}^P{w_{ij}s_j}
                      + \sum_{\jt=1}^{Q}{w_{i,P+\jt}s_{P+\jt}})                                                    \\
                    & = \sigma(\bt_i + \sum_{j=1, j \ne i}^P{w_{ij}v_j}
                      + \sum_{\jt=1}^{Q}{\wt_{i\jt}h_{\jt}})                    & \Leftarrow (\textrm{relabeling}) \\
                    & = \sigma(\bt_i + \sum_{j=1, j \ne i}^P{0 v_j}
                      + \sum_{\jt=1}^{Q}{\wt_{i\jt}h_{\jt}})                    & \Leftarrow v_i \perp \vv_{i-}    \\
                    & = \sigma(\bt_i + \sum_{\jt=1}^Q{\wt_{i\jt}h_{\jt}})                                          \\
  \Rightarrow \Pr(v_i=1|\vh) & = \sigma(\bt_i + \sum_{\jt=1}^Q{\wt_{i\jt}h_{\jt}})
\end{align*}
We are done with (\ref{eq:rbm:p(v|h)}), similar argument can be applied to obtain (\ref{eq:rbm:p(h|v)}).
\begin{framedbox}[h]
  \centering
  \caption{Vecterize RBM thermal dynamics}\label{box:vrbm}
  \begin{minipage}{1.0\linewidth}
    Unlike the futile case of BM (Box \ref{box:vgbm}), it is worthy of rewriting the thermal dynamic rules of a RBM in vector and matrix forms to facilitate software implementation, since all visible and
    hidden units can advanced in two separate parallel procedures.
    \begin{align*}
      \begin{bmatrix}
        \Pr(v_1=1|\vh) \\
        \Pr(v_2=1|\vh) \\
        \vdots \\
        \Pr(v_i=1|\vh) \\
        \vdots \\
        \Pr(v_P=1|\vh)
      \end{bmatrix} = \sigma(\vb + \mw  \vh) \textrm{, and }
      \begin{bmatrix}
        \Pr(h_1=1|\vv) \\
        \Pr(h_2=1|\vv) \\
        \vdots \\
        \Pr(h_j=1|\vv) \\
        \vdots \\
        \Pr(h_Q=1|\vv)
      \end{bmatrix} = \sigma(\vc + \mw^T\vv),
    \end{align*}
    where the $P$ dimensional $\vv$ and $Q$ dimensional vector $\vh$ represent states of visible and hidden units, respectively; $\vb$ and $\vc$ are their corresponding bias vectors; $\mw$ is a $P \times Q$
    matrix showing connections between visible and hidden units.
  \end{minipage}
\end{framedbox}
\subsection{MLE for RBM}
Much like the BM, the goal is to maximum the odds of presenting data on $P$ visible units that is close or even identical to the emprically observed sample, translated into minimizing the negative marginal probability of visible sample $\vv$ in the log scale. Since RBM is a special case of BM, it simply inherits the primative update rule of the parental BM that relies on gibbs sampling to approximate the integral over the Bolztmann distribution of all units during the negative phase, and another one over its conditional form by clumping the observed sample on the visible units during the positive phase (Eq.\,\ref{eq:gv3}). All we have to do is to relabel the machine paramters, as separated biases for two sets of units, and account for the connection graph degenerated from full connected $(P+Q) \times (P+Q)$ edges into restricted $P \times Q$:
\begin{align*}
  -\PDV{\log{\Pr(\vv)}}{w_{ij}} & = \mean{v_i h_j}{\vh|\vv} - \mean{v_i h_j}{\vvt, \vht}; \\
  -\PDV{\log{\Pr(\vv)}}{b_i} & = \mean{v_i}{\vh|\vv} - \mean{v_i}{\vvt, \vht} = \mean{v_i}{\vv} - \mean{v_i}{\vvt, \vht}; \\
  -\PDV{\log{\Pr(\vv)}}{c_j} & = \mean{h_j}{\vh|\vv} - \mean{h_j}{\vvt, \vht}; \\
  \textrm{where } i & = 1, \dots, P;\, j = 1, \dots, Q.
\end{align*}
Thanks to the restriction of hidden-hidden connection though, a major speed gain over its parental BM is immediately seen from Eq.\,\eqref{eq:rbm:p(h|v)}, that sampling of hidden units during the positive phase can start right after clumping the visible units with empirical observation because hidden units instantly reaches thermal equilibrium without any burn in; another speed up come from the batch rules reducing the time to advance the entire system from $O((P+Q)^2)$ to $O(PQ)$, which could be substantial if $P$ and $Q$ differ by large; an minor speed up can be achieved via vectorizing the sampling rules so morden softwares and hardwares can be fully engaged. Now, the one sample training algorithm for RBM can be programmed by first inheriting the algorithm for BM (Alg.\,\ref{alg:gbm1}), then improve it taking advantages of the aforementioned three speeding factors.
\begin{algorithm}[h]
  \caption{One sample update rule for Restricted Boltzmann Machine}\label{alg:rbm1}
  \begin{algorithmic}[1]
    \State Clump $P$ dimenional obsevation on $P$ visible units $\vv$ \Comment{\textbf{Positive} Phase}
    \Repeat                                                           \Comment{sampling without burn in}
        \State batch advance the state of all $h_j$                   \Comment{(Eq.\,\ref{eq:rbm:p(h|v)})}
        \State Store $\vh$
    \Until{enough sample of $\vh$ is gathered}
    \State $\mean{v_i h_j}{\vh|\vv} \approx$ proportion of times both $v_i$ and $h_j$ are on
    \State $\mean{v_i}{\vh|\vv}$ (or $\mean{v_i}{\vv}$) $\gets$ proportion of times $v_i$ is on\textsuperscript{1}
    \State $\mean{h_j}{\vh|\vv} \approx$ proportion of times $h_j$ is on
    \Statex

    \State Relex the constraint on $P$ visible units $\vv$            \Comment{\textbf{Negative} Phase}
    \Repeat                                                           \Comment{burn in}
        \State batch advance the state of all $h_j$                   \Comment{(Eq.\,\ref{eq:rbm:p(h|v)})}
        \State batch advance the state of all $v_i$                   \Comment{(Eq.\,\ref{eq:rbm:p(v|h)})}
    \Until{$\vs=(\vv, \vh)$ reaches thermal equilibrium}
    \Repeat                                                           \Comment{sampling}
        \State batch advance the state of all $h_j$                   \Comment{(Eq.\,\ref{eq:rbm:p(h|v)})}
        \State batch advance the state of all $v_i$                   \Comment{(Eq.\,\ref{eq:rbm:p(v|h)})}
    \Until{enough sample of $\vs$ is gathered}
    \State $\mean{v_i h_j}{\vvt, \vht} \approx$ proportion of times both $v_i$ and $h_j$ are on
    \State $\mean{v_i}{\vvt, \vht} \approx$ proportion of times $v_i$ is on
    \State $\mean{h_j}{\vvt, \vht} \approx$ proportion of times $h_j$ is on
    \Statex

    \State $-\Delta w_{ij} \gets \mean{v_i h_j}{\vh|\vv} - \mean{v_i v_j}{\vvt, \vht}$
    \State $-\Delta b_{i} \gets \mean{v_i}{\vh|\vv} - \mean{v_i}{\vvt, \vht}$
    \State $-\Delta c_{j} \gets \mean{h_j}{\vh|\vv} - \mean{h_j}{\vvt, \vht}$
    \State \Return $-\Delta \mw$, $-\Delta \vb$, and $-\Delta \vc$
  \end{algorithmic}
\end{algorithm} \\
Despite the positive phase skipping the burn in, and the time to advance the being shortened in general, the update rules (negative gradients) still rely on limited sampling to approximate integrals required to calculate expected values, which has made the negative gradient noisy - there are still rooms for improvement.
%
\subsection{Exact integral over hidden units}
The update rules for RBM MLE can be improved by replacing the approximated integral over $Q$ hidden units $\vh$ with explicit sum over all valid assemble of $\vh$ for both positive and negative phase, which is made possible by the hidden-hidden independence, reflected by separable visible and hidden states in the RBM energy formular (Eq.\,\ref{eq:rbm:e(s)}). The same cannot be done for a BM even if the summation over all $P+Q$ binary units is not drastically more expensive than $Q$ hidden units, because batch update does not apply to BM due to its full connection - it is pointless to sum over hidden units assemble since the states has to progress on a per-unit bases.
Back to the RBM case, review the crude one sample update rule for a general BM (Eq.\,\ref{eq:gv1}) and the energy function of a RBM (Eq.\,\ref{eq:rbm:e(s)}), the crude one sample update rule, that is, the gradient of negative log likelihood of observing $\vv$ on the visible units, with respect to machine parameters $\pEC$ has a concise form:
% \begin{align}\label{eq:rbm:l(v)}
%   -\log{\Pr(\vv)} & = -e^{\vv^T\vb} - \sum_{j=1}^Q{\log{(e^{c_j + \vv^T\vw_j}+1)}} + \mean{e^{\vvt^T\vb} + \sum_{j=1}^Q{\log{(e^{c_j + \vvt^T\vw_j}+1)}}}{\vvt}
% \end{align}
\begin{equation} \label{eq:rbm:gv1}
  -\begin{bmatrix}
    \PDV{\log{\Pr(\vv)}}{\mw} \\
    \PDV{\log{\Pr(\vv)}}{\vb} \\
    \PDV{\log{\Pr(\vv)}}{\vc}
  \end{bmatrix} = 
  \begin{bmatrix}
    -\vv\sigma(\vc^T + \vv^T\mw)      \\
    -\vv                              \\
    -\bs{I}_{\vc} \sigma(\vc + \vv^T\mw)
  \end{bmatrix} +
  \mean{\begin{bmatrix}
    \vvt\sigma(\vc^T + \vvt^T\mw)     \\
    \vvt                              \\
    \bs{I}_{\vc} \sigma(\vc + \vvt^T\mw)
  \end{bmatrix}}{\vvt}
\end{equation}
The positive phase can be accurately calculated in roughly $O(NM)$ steps, similar to the load of a single layered feed forward neural network. \\
\textbf{Derivation}: \\
Replace the place holder in the crude negative gradient (Eq.\,\ref{eq:gv1}) with RBM energy formula (Eq.\,\ref{eq:rbm:e(s)}):
\begin{align*}
  -\PDV{\log{\Pr(\vv)}}{\pEC} = -\PDV{\log{\int_{\vh}{e^{\vv^T\vb + \vc^T\vh + \vv^T\mw\vh}d\vh}}}{\pEC} + \PDV{\mean{\log{\int_{\vh}{e^{\vv^T\vbt + \vc^T\vh + \vvt^T\mw\vh}d\vh}}}{\vvt}}{\pEC},
\end{align*}
We only have to deal with positive phase since the negative phase has the same form. From the energy function, factor out terms not involving the hidden units:
\begin{align*}
  -\log{\int_{\vh}{e^{\vv^T\vb + \vc^T\vh + \vv^T\mw\vh}} d\vh} = -e^{\vv^T\vb} - \log{\int_{\vh}{e^{(\vc + \vv^T\mw)\vh}} d\vh};
\end{align*}
terms left in the energy function do not involve product bwteeen hidden units (hence separable), therefore the contribution of a hidden unit to the integral is unaffected by other hidden units; also take advantage of the fact that units are binary, thus the integral over the $j$ th. hidden units $h_j$ only involves summation over two condictions: $h_j=0$ and $h_j=1$:
\begin{align*}
  & \quad \int_{\vh}{e^{(\vc + \vv^T\mw)\vh}} d\vh \\
  & = \int_{(h_1, \dots, h_Q)} \left[\exp{\sum_{j=1}^Q{(c_j + \vv^T\vw_j)h_j}} \right] d(h_1, \dots, h_Q) \\
  & = \int_{h_1}e^{(c_1 + \vv^T\vw_1)h_1}                 \int_{h_2}e^{(c_2 + \vv^T\vw_2)h_2} \int_{h_3} \dots \int_{h_Q}e^{(c_Q + \vv^T\vw_Q)h_Q} dh_Q \dots dh_3\,dh_2\,dh_1 \\
  & = (e^{c_1+\vv^T\vw_1}+e^0)                            \int_{h_2}e^{(c_2 + \vv^T\vw_2)h_2} \int_{h_3} \dots \int_{h_Q}e^{(c_Q + \vv^T\vw_Q)h_Q} dh_Q \dots dh_3\,dh_2 \\
  & = (e^{c_1+\vv^T\vw_1}+e^0)                            (e^{c_2+\vv^T\vw_2} + e^0)          \int_{h_3} \dots \int_{h_Q}e^{(c_Q + \vv^T\vw_Q)h_Q} dh_Q \dots dh_3 \\
  & \quad \vdots \\
  & = \prod_{j=1}^Q{(e^{c_j + \vv^T\vw_j}+1)},
\end{align*}
where $\vw_j$ is the $j$ th column in the $P \times Q$ connection (weight) matrix $\mw$. Now we have
\begin{align*}
  -\log{\int_{\vh}{e^{\vv^T\vb + \vc^T\vh + \vv^T\mw\vh}} d\vh} = -e^{\vv^T\vb} - \sum_{j=1}^Q{\log{(e^{c_j + \vv^T\vw_j}+1)}}.
\end{align*}
Now it is easy to derive the gradient of positive phase w.r.t. $\pEC=\{\vb, \vc, \mw\}$:
\begin{align*}
  -\PDV{\log{\int_{\vh} e^{\vv^T\vb + \vc^T\vh + \vv^T\mw\vh}} d\vh}{\vw_j}  & = -\frac{\vv^T e^{c_j + \vv^T\vw_j}}{e^{c_j + \vv^T\vw_j}+1} = -\vv\sigma(c_j + \vv^T\vw_j) \\
  \Rightarrow
  -\PDV{\log{\int_{\vh} e^{\vv^T\vb + \vc^T\vh + \vv^T\mw\vh}} d\vh}{\mw}    & = -\vv\sigma(\vc^T + \vv^T\mw) \\
  % 
  -\PDV{\log{\int_{\vh} e^{\vv^T\vb + \vc^T\vh + \vv^T\mw\vh}} d\vh}{c_j}    & = -\frac{c_j e^{c_j + \vv^T\vw_j}}{e^{c_j + \vv^T\vw_j}+1} = -c_j\sigma(c_j + \vv^T\vw_j) \\
  \Rightarrow
  -\PDV{\log{\int_{\vh} e^{\vv^T\vb + \vc^T\vh + \vv^T\mw\vh}} d\vh}{\vc}    & = -\bs{I}_{\vc} \sigma(\vc + \vv^T\mw) \\
  % 
  \textrm{and }
  -\PDV{\log{\int_{\vh} e^{\vv^T\vb + \vc^T\vh + \vv^T\mw\vh}} d\vh}{\vb}    & = -\vv
\end{align*}
The negative phase can be done in exactly the same way with the sum rule in differentiation.
\subsection{RBM with Symbolic Library}
The primative update rules are necessary for developing both BM and RBM trainer from scratch, in case of available symbolic mathematics libraries however, such as Python-Theano and Matlab-Symbolic, it is often unnecessary, or even over-developing to implement the primative rules in Eq.\,\eqref{eq:gv3} directly through algorithm \eqref{alg:gbm1} and \eqref{alg:rbm1} . Instead, it would be more efficient and easier to just construct a crude objective function, then let the software packages to figure out the gradient, and subsequently, the update rules. 
which involves the mean of marginal distribution $\Pr(\vvt)$, posing a severe challenge to direct evaluation attempt, we instead resort to approximation via limited sampling from $\Pr(\vvt)$:
\begin{align}\label{eq:rbm:gv2}
  -\log{\Pr(\vv)} \approx -\log{\int_{\vh} e^{-E(\vv, \vh)} d\vh} + \frac{1}{|M|}\sum_{\vvt \in M}{\log{\int_{\vh} e^{-E(\vvt, \vh)}d\vh}}
\end{align}
where $M$ is the set of samples drawn from $\Pr(\vvt)$. \\
\subsection{Free Energy}
It is now helpfult to introduce the notion of ``\textbf{free energy}'' $F$, which, just likes the complete energy $E$ that corresponds to each distinct state $\vs=(\vv, \vh)$, corresponds to every distinct visible state $\vv$. \textbf{Free energy} takes the form:
\begin{align}\label{eq:f(v)}
    F(\vv) = -\log{\int_{\vh}{e^{-E(\vv, \vh)}d\vh}}.
\end{align}
Compare (\ref{eq:f(v)}) with (\ref{eq:e(s)}), we see that $F(\vv)$ in essence is the kernel of $\Pr(\vv)$ under negative log scale, which is the marginal distribution of $Pr(\vv, \vh)$ over $\vh$. Refer to equation (\ref{eq:p(s)}), $F(\vv)$ governs the system behavior in a similar manner, allbeit the only concern of $F(\vv)$ is the visible units:
\begin{align}\label{eq:p(v)|fe}
    \Pr(\vv) = \frac{e^{-F(\vv)}}{Z}, \quad\quad Z=\int_{\vv}{e^{-F(\vv)}}d\vv
\end{align}
It makes the aforementioned crude objective function expression more concise:
\begin{align}\label{eq:l(v)3}
  -\log{\Pr(\vv)} \approx F(\vv) - \frac{1}{|M|}\sum_{\vvt \in M}{F(\vvt)},
\end{align}
The update rules depends on the gradient of objective function with respect to the flexible parameters $\pEC$:
\begin{align}\label{eq:gv4}
  -\PDV{\log{\Pr(\vv)}}{\pEC} \approx \PDV{F(\vv)}{\pEC} - \PDV{\frac{1}{|M|}\sum_{\vvt \in M}{F(\vvt)}}{\pEC},
\end{align}
The negative log kernel of marginal probability $Pr(\vv)$, that is, the free energy, is simplified in a RBM:
\begin{align*}
  F(\vv) &= -\log{\sum_{\vh\in \{0,1\}^Q}{e^{\vb^T \vv + \vc^T \vh + \vh^T \mw \vv}}} \\
         &= -\log{\left[ e^{\vv^T\vb}\sum_{\vh\in \{0,1\}^Q}{e^{\vh^T(\vc + \mw \vv)}} \right]} \\
         &= -\vv^T\vb - \log{\sum_{\vh\in \{0,1\}^Q}{ \prod_{j=1}^Q{e^{h_j(c_j + \vw_j\vv)}} }}; \\
  \textrm{and} \quad & \sum_{h_1, \dots h_Q \in \{0,1\}}{\prod_{j=1}^Q{e^{h_j(c_j + \vw_j\vv)}}} \\
         &= (e^{c_1+\vw_1\vv}+e^{0}) \sum_{h_2 \dots h_Q \in\{0,1\}}{ \prod_{j=2}^Q{e^{h_j(c_j + \vw_j\vv)}} } \\
         &= (e^{c_1+\vw_1\vv}+e^{0})(e^{c_2+\vw_2\vv}+e^{0}) \sum_{h_3 \dots h_Q \in\{0,1\}}{ \prod_{j=3}^Q{e^{h_j(c_j + \vw_j\vv)}} } \\
         & \quad \vdots \\
         &= (e^{c_1+\vw_1\vv}+e^{0})(e^{c_2+\vw_2\vv}+e^{0}) \dots (e^{c_Q+\vw_Q\vv}+e^{0}) \\
         &= \prod_{j=1}^Q{(e^{c_j+\vw_j\vv} + 1)}; \\
  \Rightarrow
  F(\vv) &= -\vv^T\vb - \sum_{j=1}^Q{\log{(e^{c_j+\vw_j\vv} + 1)}} \numberthis \label{eq:fe_bin}.
\end{align*}
A symbolic library user should program the \textbf{free energy} function $F(\vv)$, the sampling procedure from $\Pr{\vv}$, the approximated crude lose (equation \ref{eq:l(v)3}), but leave the code of gradient function (equation \ref{eq:gv4}) for the library to automatically program, optimize, and even compile into low level machine language for best hardware utilization.
%
\singlespacing 
\bibliographystyle{\style}
\bibliography{ref}

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
