\documentclass[11pt]{article}
\usepackage{textcomp,bbding,subfig}
\usepackage{float,amssymb,amsmath,amsfonts,bm}
\usepackage{graphicx,cite}
\usepackage[]{natbib}
\def\style{apa}
\usepackage[usenames,pdftex,dvips]{color,xcolor}
\usepackage{multirow,tabulary,colortbl,array}
\usepackage[normalem]{ulem}
\usepackage[colorlinks,bookmarksopen,bookmarksnumbered,citecolor=blue,urlcolor=blue]{hyperref}
\usepackage{moreverb,setspace}
%
% Text layout
\topmargin -1.5cm
\oddsidemargin 0.0cm
\evensidemargin 0.0cm
\textwidth 16.5cm
\textheight 23.5cm     
%
% Remove brackets from numbering in List of References
% \makeatletter \renewcommand\@biblabel[1]{} \makeatother
\makeatletter
\renewcommand{\@biblabel}[1]{\quad#1.}
\makeatother
%
% no indent for any paragraphs
\setlength\parindent{0pt}
%
\numberwithin{equation}{section}
%
% aliasis
% FreeSurfer from Havord Unv.
\newcommand{\bs}{\boldsymbol}
\newcommand{\mean}[2]{\left\langle{#1}\right\rangle_{#2}}
% vector, matrices
\newcommand{\vs}{\bs{s}}
% others
\newcommand{\ev}[1]{\langle #1 \rangle}
% derivative
\newcommand{\DRV}[2]{\frac{d #1}{d #2}}
\newcommand{\DRC}[3]{\DRV{#1}{#2}\DRV{#2}{#3}}
\newcommand{\PDV}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\PDC}[3]{\PDV{#1}{#2}\PDV{#2}{#3}}
%
\doublespacing
\begin{document}
\title{A note on 'An Introduction to the Theory of Spin Glasses and Neural Networks'}
\maketitle
\begin{flushleft}
Xiaoran Tong\textsuperscript{1},
\\
\bigskip
\textbf{1} Department of Epidemiology and Biostatistics, Michigan State University, East Lansing, USA
%
\vskip 50ex
Correspondence: Qing Lu\\
Department of Epidemiology and Biostatistics\\
College of Human Medicine\\
Michigan State University\\
909 Fee Road\\
East Lansing, MI 48824--1030\\
\end{flushleft}
\clearpage
\section{The Ising Magnetic Systems}
\subsection{General principles of the statistical mechanics}
The state of a system is represented by $N$-d variable $\vs=[s_1, s_2, \dots, s_N]^T$. An observable quantity of the system is a function of its state $A(\vs)$. The form of $A$ is versatile, but the most basic one is called \textit{engery} $H$, a function defined on $\vs: H = H(\vs)$ that characterize each state, and further characterize the dynamic behavior of the system. In most cases, the mean value of quantity $A$ is of best interests, which can be formally obtained via a infinitely long peroid of observation:
\begin{equation} %\label{eq:mu(A,t)}
  \mean{A}{t} = \lim_{t \to \infty}\frac{1}{t} \int_0^t A(\vs^{(t)})  dt
\end{equation}
However, the equilibrium statistical mechanics states that, after a infinitely long period of observation, the system has ``visited'' its distinct states many times, and therefore the mean over time in Eq.\,\eqref{eq:mu(A,t)} can be replaced by the mean over \textit{assemble} of the states:
\begin{align}\label{eq:mu(A,s)}
  \mean{A}{\vs} = \int_{\vs} A(\vs)\Pr(\vs) d\vs.
\end{align}
Here, $\Pr(\vs)$ is the \textit{probability density function} (PDF) of the sytem states, which must satisfy
\begin{align}\label{eq:int_s{p(s)}==1}
  \int_{\vs} \Pr(\vs) d\vs = 1
\end{align}
in order to be a valid PDF. \\
To characterize the probility distribution $\Pr(\vs)$ itself, statistical mechanics introduces the concept of entropy $S$, which is defined as the mean negative logarithm of the density itself:
\begin{align}
  S = \mean{-\log{P(\vs)}}{\vs} = \int{[-\log{P(\vs)}]P(\vs)d\vs}.
\end{align}
Entropy is non-negative, it measures how un-order the system is. In general, the flatter the distribution $P$ is, the larger the entroy $S$ become (i.e.\, so un-ordered that many states have a fair chance to occue); on the countrary, a point mass distribution $\delta(s_0)$ has 0 entropy (i.e.\, extremely ordered that only one state dominants the system)

Another fundamental function on $\vs$ is the aforementioned \textit{engery} $H$, whose expectation is the mean enegy $E$:
\[ E = \ev{H(\vs)} = \int{H(\vs)P(\vs)d\vs} \]

The form of $P(\vs)$ and $H(\vs)$ cannot be arbitrary, the nature dictates that 1) without interference, the system energy $E$ is conserved; 2) when it reaches equilibrium, the entropy $S$ is at possible maximum (or, to maintain the entropy $S$, the mean engery $E$ would go as low as possible).

With these constraints, the relationship between state engery $H$ and state probability $P$ at system equilibrium  is:
\begin{equation}
  \begin{split}
    \PDV{S}{\vs} = 0 
    \quad\textrm{s.t.}\quad\int{H(\vs)P(\vs)d\vs} = E, \textrm{and} \int{P(\vs)d\vs} = 1.
  \end{split}
\end{equation}

\clearpage
\singlespacing
\bibliographystyle{\style}
\bibliography{ref}
% \printbibliography{}
%
\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
\grid
