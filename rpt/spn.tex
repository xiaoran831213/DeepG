\documentclass[11pt]{book}
\usepackage{textcomp,bbding,subfig}
\usepackage{float,amssymb,amsmath,amsfonts,bm}
\usepackage{graphicx,cite}
\usepackage[]{natbib}
\def\style{apa}
\usepackage[usenames,pdftex,dvips]{color,xcolor}
\usepackage{multirow,tabulary,colortbl,array}
\usepackage[normalem]{ulem}
\usepackage[colorlinks,bookmarksopen,bookmarksnumbered,citecolor=blue,urlcolor=blue]{hyperref}
\usepackage{moreverb,setspace}
%
% Text layout
\topmargin -1.5cm
\oddsidemargin 0.0cm
\evensidemargin 0.0cm
\textwidth 16.5cm
\textheight 23.5cm     
%
% Remove brackets from numbering in List of References
% \makeatletter \renewcommand\@biblabel[1]{} \makeatother
\makeatletter
\renewcommand{\@biblabel}[1]{\quad#1.}
\makeatother
%
% no indent for any paragraphs
\setlength\parindent{0pt}
%
\numberwithin{equation}{chapter}
%
% aliasis
% FreeSurfer from Havord Unv.
\newcommand{\bs}{\boldsymbol}
\newcommand{\mean}[2]{\left\langle{#1}\right\rangle_{#2}}
% vector, matrices
\newcommand{\vs}{\bs{s}}
% derivative
\newcommand{\DRV}[2]{\frac{d #1}{d #2}}
\newcommand{\DRC}[3]{\DRV{#1}{#2}\DRV{#2}{#3}}
\newcommand{\PDV}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\PDC}[3]{\PDV{#1}{#2}\PDV{#2}{#3}}
%
\doublespacing
\begin{document}
\title{A note on 'An Introduction to the Theory of Spin Glasses and Neural Networks'}
\maketitle
\begin{flushleft}
Xiaoran Tong\textsuperscript{1},
\\
\bigskip
\textbf{1} Department of Epidemiology and Biostatistics, Michigan State University, East Lansing, USA
%
\vskip 50ex
Correspondence: Qing Lu\\
Department of Epidemiology and Biostatistics\\
College of Human Medicine\\
Michigan State University\\
909 Fee Road\\
East Lansing, MI 48824--1030\\
\end{flushleft}
\clearpage
\chapter{The Ising Magnetic Systems}
\section{General principles of the statistical mechanics}
The state of a system is represented by $N$-d variable $\vs=[s_1, s_2, \dots, s_N]^T$. An observable quantity of the system is a function of its state $A(\vs)$. The form of $A$ is versatile, but the most basic one is called \textit{engery} $H$, a function defined on $\vs: H = H(\vs)$ that characterize each state, and further characterize the dynamic behavior of the system.

In most cases the mean quantity $A$ holds the best interests, which can be formally obtained via a infinitely long peroid of observation:
\begin{equation} \label{eq:mu(A,t)}
  \mean{A}{t} = \lim_{t \to \infty}\frac{1}{t} \int_0^t A(\vs^{(t)})  dt
\end{equation}
The equilibrium statistical mechanics states that, after a infinitely long period of observation, the system has ``visited'' its distinct states many times, and therefore the mean over time in Eq.\,\eqref{eq:mu(A,t)} can be replaced by the mean over \textit{assemble} of the states:
\begin{align}\label{eq:mu(A,s)}
  \mean{A}{\vs} = \int_{\vs} A(\vs)\Pr(\vs) d\vs.
\end{align}
Here, $\Pr(\vs)$ is the \textit{probability density function} (PDF) of the sytem states, which must satisfies
\begin{align}\label{eq:int(p)=1}
  \int_{\vs} \Pr(\vs) d\vs = 1
\end{align}
in order to be a valid PDF.

To characterize the probility distribution $\Pr(\vs)$ itself, statistical mechanics introduces the concept of entropy $S$, which is defined as the mean negative logarithm of the density itself:
\begin{align}
  S = \mean{-\log{P(\vs)}}{\vs} = \int{[-\log{P(\vs)}]P(\vs)d\vs}.
\end{align}
Entropy is non-negative, it measures how chaotic the system is. In general, the flatter the distribution $P$ is, the larger the entroy $S$ become (i.e.\, so un-ordered that many states have a fair chance to occue); on the countrary, a point mass distribution $\delta(s_0)$ has 0 entropy (i.e.\, extremely ordered that only one state dominants the system)

\textbf{work out the general form of Pr(\textbf{s})} \\
Nature dictates that:\\
(1) without interference (e.g., chane of temperature or pressure), the mean system ergery
\begin{align}
  E = \mean{H(\vs)}{\vs} = \int_{\vs} H(\vs)\Pr(\vs) d\vs
\end{align}
is conserved; 
(2) when it researches thermal equilibrium, the entrophy $S$ is at possible maximum, that is, $\PDV{S}{a}=0$. These rules, coupled with Eq.\,\eqref{eq:int(p)=1} implies the relationship between the forms of energy $H(\vs)$ and probability $\Pr(\vs)$ as
\begin{equation}
  \begin{split}
    \PDV{S}{\vs} = 0 
    \quad\textrm{s.t.}\quad\int{H(\vs)P(\vs)d\vs} = E \textrm{, and} \int{P(\vs)d\vs} = 1.
  \end{split}
\end{equation}

\clearpage
\singlespacing
\bibliographystyle{\style}
\bibliography{ref}
% \printbibliography{}
%
\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
\grid
